{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 89.11965489387512,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.44678000000000007,
        "f1": 0.42405774139116525,
        "f1_weighted": 0.42405774139116525,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.44678000000000007,
        "scores_per_experiment": [
          {
            "accuracy": 0.4432,
            "f1": 0.4128581086837859,
            "f1_weighted": 0.4128581086837859
          },
          {
            "accuracy": 0.4536,
            "f1": 0.4362083315439791,
            "f1_weighted": 0.43620833154397903
          },
          {
            "accuracy": 0.468,
            "f1": 0.4297143374330804,
            "f1_weighted": 0.42971433743308046
          },
          {
            "accuracy": 0.4484,
            "f1": 0.44175168895312933,
            "f1_weighted": 0.4417516889531293
          },
          {
            "accuracy": 0.437,
            "f1": 0.40908631376427473,
            "f1_weighted": 0.4090863137642748
          },
          {
            "accuracy": 0.4506,
            "f1": 0.42870402357493365,
            "f1_weighted": 0.42870402357493365
          },
          {
            "accuracy": 0.4334,
            "f1": 0.41082859750405804,
            "f1_weighted": 0.41082859750405804
          },
          {
            "accuracy": 0.4514,
            "f1": 0.4396235588515759,
            "f1_weighted": 0.43962355885157595
          },
          {
            "accuracy": 0.4492,
            "f1": 0.41488193691105657,
            "f1_weighted": 0.4148819369110565
          },
          {
            "accuracy": 0.433,
            "f1": 0.41692051669177876,
            "f1_weighted": 0.4169205166917787
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.44446,
        "f1": 0.42214102696443695,
        "f1_weighted": 0.42214102696443695,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.44446,
        "scores_per_experiment": [
          {
            "accuracy": 0.4336,
            "f1": 0.40320353806833475,
            "f1_weighted": 0.4032035380683348
          },
          {
            "accuracy": 0.4488,
            "f1": 0.4305457057707863,
            "f1_weighted": 0.4305457057707864
          },
          {
            "accuracy": 0.464,
            "f1": 0.42430424103687503,
            "f1_weighted": 0.42430424103687503
          },
          {
            "accuracy": 0.4442,
            "f1": 0.4381740531500947,
            "f1_weighted": 0.4381740531500947
          },
          {
            "accuracy": 0.4406,
            "f1": 0.4156932047502909,
            "f1_weighted": 0.415693204750291
          },
          {
            "accuracy": 0.4572,
            "f1": 0.4340821005328042,
            "f1_weighted": 0.43408210053280416
          },
          {
            "accuracy": 0.437,
            "f1": 0.4166405917478004,
            "f1_weighted": 0.4166405917478004
          },
          {
            "accuracy": 0.4414,
            "f1": 0.43121042189248604,
            "f1_weighted": 0.431210421892486
          },
          {
            "accuracy": 0.4458,
            "f1": 0.41170102764187205,
            "f1_weighted": 0.41170102764187205
          },
          {
            "accuracy": 0.432,
            "f1": 0.41585538505302555,
            "f1_weighted": 0.4158553850530255
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}