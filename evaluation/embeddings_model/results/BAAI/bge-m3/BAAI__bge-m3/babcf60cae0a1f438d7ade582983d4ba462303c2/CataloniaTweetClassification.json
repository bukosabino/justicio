{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "evaluation_time": 22.496618270874023,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.4875999999999999,
        "f1": 0.495389318235397,
        "f1_weighted": 0.47891884944166285,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4875999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.5365,
            "f1": 0.5446280613952249,
            "f1_weighted": 0.5289936214084807
          },
          {
            "accuracy": 0.4645,
            "f1": 0.47137929338019835,
            "f1_weighted": 0.45125851157391206
          },
          {
            "accuracy": 0.441,
            "f1": 0.4423184099500607,
            "f1_weighted": 0.43361017360084164
          },
          {
            "accuracy": 0.4865,
            "f1": 0.5006347979068946,
            "f1_weighted": 0.4830379744816243
          },
          {
            "accuracy": 0.4785,
            "f1": 0.4794393853836449,
            "f1_weighted": 0.4685082062301844
          },
          {
            "accuracy": 0.5285,
            "f1": 0.5408500269333003,
            "f1_weighted": 0.5252252868634425
          },
          {
            "accuracy": 0.5215,
            "f1": 0.5334697717156517,
            "f1_weighted": 0.5110434772460865
          },
          {
            "accuracy": 0.472,
            "f1": 0.4752905999468883,
            "f1_weighted": 0.4603400353982301
          },
          {
            "accuracy": 0.456,
            "f1": 0.4575064934604902,
            "f1_weighted": 0.45021574487739774
          },
          {
            "accuracy": 0.491,
            "f1": 0.5083763422816154,
            "f1_weighted": 0.47695546273642897
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.48850000000000005,
        "f1": 0.4947283256005882,
        "f1_weighted": 0.48115402766318677,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.48850000000000005,
        "scores_per_experiment": [
          {
            "accuracy": 0.539,
            "f1": 0.5464470729825366,
            "f1_weighted": 0.5336021569805925
          },
          {
            "accuracy": 0.484,
            "f1": 0.4894218537719817,
            "f1_weighted": 0.47470516066031826
          },
          {
            "accuracy": 0.445,
            "f1": 0.4455307659258912,
            "f1_weighted": 0.43910157608256967
          },
          {
            "accuracy": 0.498,
            "f1": 0.5070390548133686,
            "f1_weighted": 0.4952619526445418
          },
          {
            "accuracy": 0.4595,
            "f1": 0.4639483576499602,
            "f1_weighted": 0.45036650516929616
          },
          {
            "accuracy": 0.5245,
            "f1": 0.5407858817012889,
            "f1_weighted": 0.5213218129077658
          },
          {
            "accuracy": 0.5095,
            "f1": 0.5196772939931399,
            "f1_weighted": 0.5028498831598263
          },
          {
            "accuracy": 0.4725,
            "f1": 0.4708719174588281,
            "f1_weighted": 0.4612039498229505
          },
          {
            "accuracy": 0.44,
            "f1": 0.4423566083741999,
            "f1_weighted": 0.4321500582434104
          },
          {
            "accuracy": 0.513,
            "f1": 0.5212044493346871,
            "f1_weighted": 0.5009772209605959
          }
        ]
      }
    ]
  },
  "task_name": "CataloniaTweetClassification"
}