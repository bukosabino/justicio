{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 10.824077606201172,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.9183789192795198,
        "f1": 0.9125084267753119,
        "f1_weighted": 0.9181251805850845,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.9183789192795198,
        "scores_per_experiment": [
          {
            "accuracy": 0.9362908605737158,
            "f1": 0.9308539277147656,
            "f1_weighted": 0.9362089935650718
          },
          {
            "accuracy": 0.9016010673782522,
            "f1": 0.8945649587237674,
            "f1_weighted": 0.9011989713674253
          },
          {
            "accuracy": 0.9249499666444296,
            "f1": 0.9214388031500154,
            "f1_weighted": 0.9251358742918964
          },
          {
            "accuracy": 0.9179452968645764,
            "f1": 0.9108133592737104,
            "f1_weighted": 0.9176579135328727
          },
          {
            "accuracy": 0.9119412941961308,
            "f1": 0.9062853507390213,
            "f1_weighted": 0.9113575364567782
          },
          {
            "accuracy": 0.9272848565710473,
            "f1": 0.9229018879547749,
            "f1_weighted": 0.927101991099451
          },
          {
            "accuracy": 0.9122748498999332,
            "f1": 0.9071886871692388,
            "f1_weighted": 0.912118802972318
          },
          {
            "accuracy": 0.9202801867911942,
            "f1": 0.914854662047599,
            "f1_weighted": 0.9203755598145666
          },
          {
            "accuracy": 0.9176117411607738,
            "f1": 0.9111876537946383,
            "f1_weighted": 0.9174438365478041
          },
          {
            "accuracy": 0.9136090727151435,
            "f1": 0.9049949771855882,
            "f1_weighted": 0.912652326202661
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.9167648984937788,
        "f1": 0.9151690563394344,
        "f1_weighted": 0.9163419092915351,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.9167648984937788,
        "scores_per_experiment": [
          {
            "accuracy": 0.9430255402750491,
            "f1": 0.9430157969374904,
            "f1_weighted": 0.9428002532060559
          },
          {
            "accuracy": 0.9004584151931893,
            "f1": 0.898756763052187,
            "f1_weighted": 0.9009253993550324
          },
          {
            "accuracy": 0.9305828421741977,
            "f1": 0.9315398707026387,
            "f1_weighted": 0.9304914018258688
          },
          {
            "accuracy": 0.9037328094302554,
            "f1": 0.9008378583695488,
            "f1_weighted": 0.9033764381281825
          },
          {
            "accuracy": 0.9056974459724951,
            "f1": 0.9050508927567276,
            "f1_weighted": 0.9043298908088192
          },
          {
            "accuracy": 0.9390962671905697,
            "f1": 0.9382265049600694,
            "f1_weighted": 0.938910170183542
          },
          {
            "accuracy": 0.908316961362148,
            "f1": 0.9062969177982023,
            "f1_weighted": 0.9077502841379549
          },
          {
            "accuracy": 0.9142108709888671,
            "f1": 0.9113885964330617,
            "f1_weighted": 0.9142924523310937
          },
          {
            "accuracy": 0.9122462344466273,
            "f1": 0.9097908275107668,
            "f1_weighted": 0.9111483479925627
          },
          {
            "accuracy": 0.9102815979043877,
            "f1": 0.9067865348736504,
            "f1_weighted": 0.909394454946237
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}