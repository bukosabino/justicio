{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 29.898176431655884,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.6644096064042696,
        "f1": 0.4488866093717652,
        "f1_weighted": 0.700051965759593,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6644096064042696,
        "scores_per_experiment": [
          {
            "accuracy": 0.6387591727818546,
            "f1": 0.42735975482733596,
            "f1_weighted": 0.668545638844319
          },
          {
            "accuracy": 0.6847898599066043,
            "f1": 0.4485453420050805,
            "f1_weighted": 0.7205127873937188
          },
          {
            "accuracy": 0.6804536357571714,
            "f1": 0.4561783115132103,
            "f1_weighted": 0.7096556876504303
          },
          {
            "accuracy": 0.6524349566377585,
            "f1": 0.43977668509705514,
            "f1_weighted": 0.6855732997891514
          },
          {
            "accuracy": 0.6697798532354903,
            "f1": 0.4623431669597747,
            "f1_weighted": 0.701098190352369
          },
          {
            "accuracy": 0.675783855903936,
            "f1": 0.45333566359938254,
            "f1_weighted": 0.7117802808562116
          },
          {
            "accuracy": 0.6891260840560374,
            "f1": 0.44821198126938516,
            "f1_weighted": 0.7275149220334678
          },
          {
            "accuracy": 0.6684456304202802,
            "f1": 0.4686355825536871,
            "f1_weighted": 0.7148380400687169
          },
          {
            "accuracy": 0.6220813875917278,
            "f1": 0.4317942763136276,
            "f1_weighted": 0.6612177531113019
          },
          {
            "accuracy": 0.6624416277518346,
            "f1": 0.4526853295791135,
            "f1_weighted": 0.6997830574962438
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6766208251473477,
        "f1": 0.4369630170320039,
        "f1_weighted": 0.7075650019192082,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6766208251473477,
        "scores_per_experiment": [
          {
            "accuracy": 0.6450556647020301,
            "f1": 0.43011625621006044,
            "f1_weighted": 0.6749545936602348
          },
          {
            "accuracy": 0.6922069417157826,
            "f1": 0.44607665105209493,
            "f1_weighted": 0.7234065429265448
          },
          {
            "accuracy": 0.6856581532416502,
            "f1": 0.4277651246246946,
            "f1_weighted": 0.7100797973049608
          },
          {
            "accuracy": 0.6633922724296005,
            "f1": 0.4513594963942233,
            "f1_weighted": 0.6903332608806062
          },
          {
            "accuracy": 0.6843483955468238,
            "f1": 0.41048463209498315,
            "f1_weighted": 0.7090143714592488
          },
          {
            "accuracy": 0.6954813359528488,
            "f1": 0.451414846724882,
            "f1_weighted": 0.7292903271522736
          },
          {
            "accuracy": 0.7118533071381794,
            "f1": 0.4550512207248254,
            "f1_weighted": 0.7435826815964672
          },
          {
            "accuracy": 0.6817288801571709,
            "f1": 0.46056565795829646,
            "f1_weighted": 0.7198513277215912
          },
          {
            "accuracy": 0.6240995415848068,
            "f1": 0.4103954855273591,
            "f1_weighted": 0.6615954047831369
          },
          {
            "accuracy": 0.6823837590045841,
            "f1": 0.4264007990086195,
            "f1_weighted": 0.7135417117070183
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}