{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 14.426787614822388,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.721990585070612,
        "f1": 0.7152998907106446,
        "f1_weighted": 0.7144036628076448,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.721990585070612,
        "scores_per_experiment": [
          {
            "accuracy": 0.7390719569603228,
            "f1": 0.7356973675537498,
            "f1_weighted": 0.7334166152385508
          },
          {
            "accuracy": 0.7404169468728985,
            "f1": 0.7345313311432703,
            "f1_weighted": 0.7314614958081921
          },
          {
            "accuracy": 0.7222595830531271,
            "f1": 0.7036423152088521,
            "f1_weighted": 0.7108669268027763
          },
          {
            "accuracy": 0.7027572293207801,
            "f1": 0.698765248644501,
            "f1_weighted": 0.6974345698615605
          },
          {
            "accuracy": 0.7256220578345662,
            "f1": 0.715590643049413,
            "f1_weighted": 0.713421421501628
          },
          {
            "accuracy": 0.7084734364492267,
            "f1": 0.6976943855472375,
            "f1_weighted": 0.699243074656696
          },
          {
            "accuracy": 0.7125084061869535,
            "f1": 0.7043251848783254,
            "f1_weighted": 0.7021422041176608
          },
          {
            "accuracy": 0.7088096839273705,
            "f1": 0.7087016498534129,
            "f1_weighted": 0.7041987374939753
          },
          {
            "accuracy": 0.7293207800941492,
            "f1": 0.7319291838529053,
            "f1_weighted": 0.7248123677713798
          },
          {
            "accuracy": 0.730665770006725,
            "f1": 0.7221215973747787,
            "f1_weighted": 0.7270392148240279
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7224790949335957,
        "f1": 0.7122282114515955,
        "f1_weighted": 0.7146555718791052,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.7224790949335957,
        "scores_per_experiment": [
          {
            "accuracy": 0.7388096409247418,
            "f1": 0.7337793572622747,
            "f1_weighted": 0.7313949597256444
          },
          {
            "accuracy": 0.7383177570093458,
            "f1": 0.7315208612473253,
            "f1_weighted": 0.7316812478627228
          },
          {
            "accuracy": 0.7166748647319232,
            "f1": 0.701424795498779,
            "f1_weighted": 0.7070608231646982
          },
          {
            "accuracy": 0.6930644367929168,
            "f1": 0.6817796060688871,
            "f1_weighted": 0.6829238430914637
          },
          {
            "accuracy": 0.7314313821938022,
            "f1": 0.7180767079084828,
            "f1_weighted": 0.7223795285667627
          },
          {
            "accuracy": 0.7073290703394,
            "f1": 0.6933149555207739,
            "f1_weighted": 0.6977281802058393
          },
          {
            "accuracy": 0.7088047220855878,
            "f1": 0.693270250914662,
            "f1_weighted": 0.6989967297825418
          },
          {
            "accuracy": 0.7147073290703394,
            "f1": 0.7096624422668026,
            "f1_weighted": 0.70640016702009
          },
          {
            "accuracy": 0.7432365961633055,
            "f1": 0.742371505468767,
            "f1_weighted": 0.7387450406157731
          },
          {
            "accuracy": 0.7324151500245942,
            "f1": 0.7170816323592007,
            "f1_weighted": 0.7292451987555165
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}