{
  "dataset_revision": "8f95949846bb9e33c6aaf730ccfdb8fe6bcfb7a9",
  "evaluation_time": 3.0023152828216553,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.6253,
        "ap": 0.35331834223362935,
        "ap_weighted": 0.35331834223362935,
        "f1": 0.5813968427602964,
        "f1_weighted": 0.6343096217751171,
        "hf_subset": "spa",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6253,
        "scores_per_experiment": [
          {
            "accuracy": 0.584,
            "ap": 0.31834577876845915,
            "ap_weighted": 0.31834577876845915,
            "f1": 0.5378517215023374,
            "f1_weighted": 0.597435574752484
          },
          {
            "accuracy": 0.657,
            "ap": 0.37961623004078243,
            "ap_weighted": 0.37961623004078243,
            "f1": 0.6197469931742923,
            "f1_weighted": 0.6683068231579625
          },
          {
            "accuracy": 0.615,
            "ap": 0.378066954528493,
            "ap_weighted": 0.378066954528493,
            "f1": 0.5994552591524474,
            "f1_weighted": 0.6316494432428102
          },
          {
            "accuracy": 0.592,
            "ap": 0.339672510348186,
            "ap_weighted": 0.339672510348186,
            "f1": 0.5624195624195625,
            "f1_weighted": 0.6088380952380953
          },
          {
            "accuracy": 0.617,
            "ap": 0.34544720539178975,
            "ap_weighted": 0.34544720539178975,
            "f1": 0.577146478447167,
            "f1_weighted": 0.6301114191427887
          },
          {
            "accuracy": 0.652,
            "ap": 0.3639063113392722,
            "ap_weighted": 0.3639063113392722,
            "f1": 0.6046730373379501,
            "f1_weighted": 0.6604805540030263
          },
          {
            "accuracy": 0.623,
            "ap": 0.34612377390445276,
            "ap_weighted": 0.34612377390445276,
            "f1": 0.579690933476335,
            "f1_weighted": 0.6347379713008064
          },
          {
            "accuracy": 0.589,
            "ap": 0.37370868213346087,
            "ap_weighted": 0.37370868213346087,
            "f1": 0.5809026195115834,
            "f1_weighted": 0.6046704701538425
          },
          {
            "accuracy": 0.645,
            "ap": 0.31248110669911616,
            "ap_weighted": 0.31248110669911616,
            "f1": 0.5310132359954607,
            "f1_weighted": 0.6253471096543898
          },
          {
            "accuracy": 0.679,
            "ap": 0.37581486918228135,
            "ap_weighted": 0.37581486918228135,
            "f1": 0.621068586585828,
            "f1_weighted": 0.681518757104964
          }
        ]
      }
    ]
  },
  "task_name": "MultiHateClassification"
}