{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 7.478406190872192,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.7604395604395604,
          "accuracy_threshold": 0.6557025909423828,
          "ap": 0.8076605260070395,
          "f1": 0.7773279352226721,
          "f1_threshold": 0.6379867792129517,
          "precision": 0.72,
          "recall": 0.844574780058651
        },
        "dot": {
          "accuracy": 0.7604395604395604,
          "accuracy_threshold": 0.6557024717330933,
          "ap": 0.8076605260070395,
          "f1": 0.7773279352226721,
          "f1_threshold": 0.6379867792129517,
          "precision": 0.72,
          "recall": 0.844574780058651
        },
        "euclidean": {
          "accuracy": 0.7604395604395604,
          "accuracy_threshold": 0.8298161625862122,
          "ap": 0.8076605260070395,
          "f1": 0.7773279352226721,
          "f1_threshold": 0.8508973717689514,
          "precision": 0.72,
          "recall": 0.844574780058651
        },
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.8076605260070395,
        "manhattan": {
          "accuracy": 0.7582417582417582,
          "accuracy_threshold": 20.810562133789062,
          "ap": 0.8073691355948076,
          "f1": 0.7731204258150365,
          "f1_threshold": 21.702495574951172,
          "precision": 0.707673568818514,
          "recall": 0.8519061583577713
        },
        "max": {
          "accuracy": 0.7604395604395604,
          "ap": 0.8076605260070395,
          "f1": 0.7773279352226721
        },
        "similarity": {
          "accuracy": 0.7604395604395604,
          "accuracy_threshold": 0.6557024717330933,
          "ap": 0.8076605260070395,
          "f1": 0.7773279352226721,
          "f1_threshold": 0.6379868984222412,
          "precision": 0.72,
          "recall": 0.844574780058651
        }
      }
    ],
    "validation": [
      {
        "cosine": {
          "accuracy": 0.7721611721611722,
          "accuracy_threshold": 0.674301028251648,
          "ap": 0.83101273867086,
          "f1": 0.7692307692307693,
          "f1_threshold": 0.6320723295211792,
          "precision": 0.7125,
          "recall": 0.8357771260997068
        },
        "dot": {
          "accuracy": 0.7721611721611722,
          "accuracy_threshold": 0.674301028251648,
          "ap": 0.83101273867086,
          "f1": 0.7692307692307693,
          "f1_threshold": 0.6320723295211792,
          "precision": 0.7125,
          "recall": 0.8357771260997068
        },
        "euclidean": {
          "accuracy": 0.7721611721611722,
          "accuracy_threshold": 0.8070923089981079,
          "ap": 0.83101273867086,
          "f1": 0.7692307692307693,
          "f1_threshold": 0.8578200936317444,
          "precision": 0.7125,
          "recall": 0.8357771260997068
        },
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.83101273867086,
        "manhattan": {
          "accuracy": 0.7648351648351648,
          "accuracy_threshold": 20.66407012939453,
          "ap": 0.8295791594338434,
          "f1": 0.7671043538355218,
          "f1_threshold": 21.42278480529785,
          "precision": 0.7254901960784313,
          "recall": 0.8137829912023461
        },
        "max": {
          "accuracy": 0.7721611721611722,
          "ap": 0.83101273867086,
          "f1": 0.7692307692307693
        },
        "similarity": {
          "accuracy": 0.7721611721611722,
          "accuracy_threshold": 0.6743011474609375,
          "ap": 0.83101273867086,
          "f1": 0.7692307692307693,
          "f1_threshold": 0.6320723295211792,
          "precision": 0.7125,
          "recall": 0.8357771260997068
        }
      }
    ]
  },
  "task_name": "XNLI"
}