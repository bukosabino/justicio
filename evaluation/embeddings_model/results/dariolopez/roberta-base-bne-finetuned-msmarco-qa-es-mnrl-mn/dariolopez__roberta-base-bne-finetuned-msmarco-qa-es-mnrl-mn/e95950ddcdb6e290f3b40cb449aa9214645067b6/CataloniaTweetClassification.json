{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "evaluation_time": 6.340556859970093,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.48369999999999996,
        "f1": 0.49314220549288346,
        "f1_weighted": 0.47738918261400326,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.48369999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.508,
            "f1": 0.5239339940412745,
            "f1_weighted": 0.5068278754089796
          },
          {
            "accuracy": 0.5595,
            "f1": 0.5662116415345994,
            "f1_weighted": 0.5549628277570985
          },
          {
            "accuracy": 0.404,
            "f1": 0.4047880799953423,
            "f1_weighted": 0.3959503836585128
          },
          {
            "accuracy": 0.4405,
            "f1": 0.45097274364264733,
            "f1_weighted": 0.42405694706815533
          },
          {
            "accuracy": 0.436,
            "f1": 0.4416859694200371,
            "f1_weighted": 0.4247120136944094
          },
          {
            "accuracy": 0.502,
            "f1": 0.5178034634220223,
            "f1_weighted": 0.5004404007776233
          },
          {
            "accuracy": 0.531,
            "f1": 0.5443296988711129,
            "f1_weighted": 0.5273419265492028
          },
          {
            "accuracy": 0.4765,
            "f1": 0.46929255516978013,
            "f1_weighted": 0.4638450444273975
          },
          {
            "accuracy": 0.4665,
            "f1": 0.46983268345989443,
            "f1_weighted": 0.46164094361273644
          },
          {
            "accuracy": 0.513,
            "f1": 0.5425712253721241,
            "f1_weighted": 0.5141134631859173
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.47830000000000006,
        "f1": 0.48867510346236365,
        "f1_weighted": 0.47308684157353487,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.47830000000000006,
        "scores_per_experiment": [
          {
            "accuracy": 0.4855,
            "f1": 0.5008230844818334,
            "f1_weighted": 0.48572150377224377
          },
          {
            "accuracy": 0.5415,
            "f1": 0.5514039692671057,
            "f1_weighted": 0.53638802152537
          },
          {
            "accuracy": 0.409,
            "f1": 0.41284315995999094,
            "f1_weighted": 0.4018208895400104
          },
          {
            "accuracy": 0.443,
            "f1": 0.4523266259795151,
            "f1_weighted": 0.43007488967741986
          },
          {
            "accuracy": 0.449,
            "f1": 0.4524637222154739,
            "f1_weighted": 0.4376239848783541
          },
          {
            "accuracy": 0.4885,
            "f1": 0.5091919915413213,
            "f1_weighted": 0.4889408574644429
          },
          {
            "accuracy": 0.526,
            "f1": 0.5445752924542642,
            "f1_weighted": 0.5241103554190435
          },
          {
            "accuracy": 0.483,
            "f1": 0.47387804262954386,
            "f1_weighted": 0.4727274184486702
          },
          {
            "accuracy": 0.4515,
            "f1": 0.4553576513763769,
            "f1_weighted": 0.4461860175626584
          },
          {
            "accuracy": 0.506,
            "f1": 0.5338874947182114,
            "f1_weighted": 0.5072744774471358
          }
        ]
      }
    ]
  },
  "task_name": "CataloniaTweetClassification"
}