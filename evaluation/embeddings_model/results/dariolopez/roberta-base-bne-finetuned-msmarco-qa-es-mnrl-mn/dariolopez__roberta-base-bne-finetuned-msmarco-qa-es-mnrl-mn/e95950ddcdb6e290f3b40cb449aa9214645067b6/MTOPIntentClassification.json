{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 30.784114122390747,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.5307538358905937,
        "f1": 0.357687651215255,
        "f1_weighted": 0.5810878782467117,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.5307538358905937,
        "scores_per_experiment": [
          {
            "accuracy": 0.5,
            "f1": 0.34983407398313976,
            "f1_weighted": 0.5493829950344079
          },
          {
            "accuracy": 0.5446964643095397,
            "f1": 0.35955115654340963,
            "f1_weighted": 0.5984362126288763
          },
          {
            "accuracy": 0.5416944629753169,
            "f1": 0.3670630634303175,
            "f1_weighted": 0.5915072683913849
          },
          {
            "accuracy": 0.5116744496330887,
            "f1": 0.3579615573818917,
            "f1_weighted": 0.5600647192546024
          },
          {
            "accuracy": 0.5493662441627751,
            "f1": 0.3724615031857277,
            "f1_weighted": 0.601397345181211
          },
          {
            "accuracy": 0.5493662441627751,
            "f1": 0.36071248217024,
            "f1_weighted": 0.5983892433893151
          },
          {
            "accuracy": 0.5370246831220814,
            "f1": 0.3631966160961398,
            "f1_weighted": 0.5853315330062412
          },
          {
            "accuracy": 0.505003335557038,
            "f1": 0.3282055066433297,
            "f1_weighted": 0.5541596005318513
          },
          {
            "accuracy": 0.5350233488992662,
            "f1": 0.35643496505846284,
            "f1_weighted": 0.584814614951082
          },
          {
            "accuracy": 0.533689126084056,
            "f1": 0.3614555876598911,
            "f1_weighted": 0.5873952500981453
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5355599214145383,
        "f1": 0.31035764025478496,
        "f1_weighted": 0.5842391472689267,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.5355599214145383,
        "scores_per_experiment": [
          {
            "accuracy": 0.5212835625409299,
            "f1": 0.2971645185530584,
            "f1_weighted": 0.5713918052161404
          },
          {
            "accuracy": 0.5592665356908972,
            "f1": 0.32945281662054515,
            "f1_weighted": 0.607772114225599
          },
          {
            "accuracy": 0.5468238375900458,
            "f1": 0.3012293741690168,
            "f1_weighted": 0.6018896138124327
          },
          {
            "accuracy": 0.49181401440733463,
            "f1": 0.29686040263842517,
            "f1_weighted": 0.5423300999716718
          },
          {
            "accuracy": 0.5605762933857237,
            "f1": 0.32604099720484886,
            "f1_weighted": 0.6097359738888037
          },
          {
            "accuracy": 0.5415848068107401,
            "f1": 0.3154138835961403,
            "f1_weighted": 0.5912396018393782
          },
          {
            "accuracy": 0.5428945645055665,
            "f1": 0.30410409518182807,
            "f1_weighted": 0.5874473179992138
          },
          {
            "accuracy": 0.5206286836935167,
            "f1": 0.29679399579972066,
            "f1_weighted": 0.5746672172802358
          },
          {
            "accuracy": 0.5212835625409299,
            "f1": 0.31645651233178623,
            "f1_weighted": 0.5631378468960507
          },
          {
            "accuracy": 0.5494433529796987,
            "f1": 0.3200598064524798,
            "f1_weighted": 0.5927798815597409
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}