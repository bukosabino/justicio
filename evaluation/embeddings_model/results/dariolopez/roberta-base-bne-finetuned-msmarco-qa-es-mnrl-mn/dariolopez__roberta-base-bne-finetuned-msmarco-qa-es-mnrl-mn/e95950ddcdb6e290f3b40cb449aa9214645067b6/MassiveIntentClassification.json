{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 17.413422346115112,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.5473100201748486,
        "f1": 0.5388759211649171,
        "f1_weighted": 0.5519049835098329,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.5473100201748486,
        "scores_per_experiment": [
          {
            "accuracy": 0.5574983187626092,
            "f1": 0.5492824703516187,
            "f1_weighted": 0.5645344130206177
          },
          {
            "accuracy": 0.5729657027572294,
            "f1": 0.5537351000218513,
            "f1_weighted": 0.574886714491984
          },
          {
            "accuracy": 0.5521183591123067,
            "f1": 0.5426610777227577,
            "f1_weighted": 0.5497859402007603
          },
          {
            "accuracy": 0.5295897780766644,
            "f1": 0.5198597584160835,
            "f1_weighted": 0.5317569678824489
          },
          {
            "accuracy": 0.5622057834566241,
            "f1": 0.538414255108816,
            "f1_weighted": 0.565013513742218
          },
          {
            "accuracy": 0.5450571620712845,
            "f1": 0.5358992659739907,
            "f1_weighted": 0.5496204295839354
          },
          {
            "accuracy": 0.5295897780766644,
            "f1": 0.5261625561873087,
            "f1_weighted": 0.5380715657764722
          },
          {
            "accuracy": 0.5268997982515131,
            "f1": 0.5266104020681593,
            "f1_weighted": 0.5316058382624554
          },
          {
            "accuracy": 0.5416946872898454,
            "f1": 0.5404662162401142,
            "f1_weighted": 0.5476922357953111
          },
          {
            "accuracy": 0.5554808338937458,
            "f1": 0.5556681095584713,
            "f1_weighted": 0.5660822163421263
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5653221839645844,
        "f1": 0.5533038433464216,
        "f1_weighted": 0.5663488473056314,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.5653221839645844,
        "scores_per_experiment": [
          {
            "accuracy": 0.5764879488440728,
            "f1": 0.5584165520957501,
            "f1_weighted": 0.5794168650923822
          },
          {
            "accuracy": 0.6000983767830792,
            "f1": 0.5712908023060943,
            "f1_weighted": 0.5989635997433759
          },
          {
            "accuracy": 0.5696015740285293,
            "f1": 0.5593159334936791,
            "f1_weighted": 0.5629311913108553
          },
          {
            "accuracy": 0.5533694048204624,
            "f1": 0.5424829038576705,
            "f1_weighted": 0.5509814686497979
          },
          {
            "accuracy": 0.5863256271519921,
            "f1": 0.5693034425073245,
            "f1_weighted": 0.5876012568688049
          },
          {
            "accuracy": 0.5666502705361535,
            "f1": 0.5557656016404374,
            "f1_weighted": 0.5713941346089588
          },
          {
            "accuracy": 0.5268076733890802,
            "f1": 0.5377267916464388,
            "f1_weighted": 0.5278118497653308
          },
          {
            "accuracy": 0.5400885391047713,
            "f1": 0.5345706905104906,
            "f1_weighted": 0.539250437532577
          },
          {
            "accuracy": 0.5636989670437776,
            "f1": 0.5506111887793386,
            "f1_weighted": 0.5664509396398614
          },
          {
            "accuracy": 0.5700934579439252,
            "f1": 0.5535545266269916,
            "f1_weighted": 0.5786867298443702
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}