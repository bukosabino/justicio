{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 28.858722448349,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.42702,
        "f1": 0.4071323003968025,
        "f1_weighted": 0.40713230039680237,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.42702,
        "scores_per_experiment": [
          {
            "accuracy": 0.4424,
            "f1": 0.4081103611816884,
            "f1_weighted": 0.4081103611816883
          },
          {
            "accuracy": 0.4394,
            "f1": 0.4193673747607381,
            "f1_weighted": 0.41936737476073804
          },
          {
            "accuracy": 0.4524,
            "f1": 0.4178417859287327,
            "f1_weighted": 0.41784178592873267
          },
          {
            "accuracy": 0.4328,
            "f1": 0.43066570602606546,
            "f1_weighted": 0.4306657060260654
          },
          {
            "accuracy": 0.418,
            "f1": 0.39849358192686346,
            "f1_weighted": 0.39849358192686346
          },
          {
            "accuracy": 0.4264,
            "f1": 0.40572640063745374,
            "f1_weighted": 0.4057264006374538
          },
          {
            "accuracy": 0.419,
            "f1": 0.4041658526203714,
            "f1_weighted": 0.4041658526203714
          },
          {
            "accuracy": 0.4218,
            "f1": 0.4120876479014086,
            "f1_weighted": 0.41208764790140856
          },
          {
            "accuracy": 0.4306,
            "f1": 0.39639273202273795,
            "f1_weighted": 0.396392732022738
          },
          {
            "accuracy": 0.3874,
            "f1": 0.37847156096196394,
            "f1_weighted": 0.378471560961964
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4245,
        "f1": 0.40573866420994165,
        "f1_weighted": 0.40573866420994176,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4245,
        "scores_per_experiment": [
          {
            "accuracy": 0.4362,
            "f1": 0.4046647362461015,
            "f1_weighted": 0.40466473624610155
          },
          {
            "accuracy": 0.4346,
            "f1": 0.41676401455719275,
            "f1_weighted": 0.4167640145571928
          },
          {
            "accuracy": 0.4586,
            "f1": 0.4246623380704193,
            "f1_weighted": 0.42466233807041937
          },
          {
            "accuracy": 0.4212,
            "f1": 0.41960024687627595,
            "f1_weighted": 0.41960024687627595
          },
          {
            "accuracy": 0.4138,
            "f1": 0.3947515879151939,
            "f1_weighted": 0.39475158791519394
          },
          {
            "accuracy": 0.427,
            "f1": 0.4088668999283883,
            "f1_weighted": 0.40886689992838826
          },
          {
            "accuracy": 0.4204,
            "f1": 0.40584372454838025,
            "f1_weighted": 0.4058437245483803
          },
          {
            "accuracy": 0.4166,
            "f1": 0.4091252945946275,
            "f1_weighted": 0.40912529459462754
          },
          {
            "accuracy": 0.4246,
            "f1": 0.3880922083648488,
            "f1_weighted": 0.3880922083648488
          },
          {
            "accuracy": 0.392,
            "f1": 0.38501559099798877,
            "f1_weighted": 0.38501559099798877
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}