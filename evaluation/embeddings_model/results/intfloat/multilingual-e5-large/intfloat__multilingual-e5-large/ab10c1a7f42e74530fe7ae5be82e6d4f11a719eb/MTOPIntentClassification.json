{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 19.99280548095703,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.6673782521681121,
        "f1": 0.4282498959016361,
        "f1_weighted": 0.704250775214722,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6673782521681121,
        "scores_per_experiment": [
          {
            "accuracy": 0.6647765176784523,
            "f1": 0.4146055186730349,
            "f1_weighted": 0.6984131322505579
          },
          {
            "accuracy": 0.69079386257505,
            "f1": 0.43953091147026513,
            "f1_weighted": 0.7327953693084361
          },
          {
            "accuracy": 0.7024683122081388,
            "f1": 0.4411675709173595,
            "f1_weighted": 0.7307365160345759
          },
          {
            "accuracy": 0.6501000667111407,
            "f1": 0.4305955652036859,
            "f1_weighted": 0.685570226438838
          },
          {
            "accuracy": 0.6641094062708472,
            "f1": 0.42274769477044605,
            "f1_weighted": 0.697283615992139
          },
          {
            "accuracy": 0.6794529686457639,
            "f1": 0.42214957934598013,
            "f1_weighted": 0.7174679123907838
          },
          {
            "accuracy": 0.6637758505670447,
            "f1": 0.4309662718837306,
            "f1_weighted": 0.7009665397322848
          },
          {
            "accuracy": 0.6477651767845231,
            "f1": 0.43871698248534147,
            "f1_weighted": 0.6930762724348851
          },
          {
            "accuracy": 0.6454302868579053,
            "f1": 0.42698810043249863,
            "f1_weighted": 0.6836218015362063
          },
          {
            "accuracy": 0.6651100733822548,
            "f1": 0.41503076383401866,
            "f1_weighted": 0.7025763660285136
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6707924034053699,
        "f1": 0.4333134780687608,
        "f1_weighted": 0.7010576278211016,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6707924034053699,
        "scores_per_experiment": [
          {
            "accuracy": 0.6633922724296005,
            "f1": 0.4405047476139423,
            "f1_weighted": 0.6922672298826147
          },
          {
            "accuracy": 0.6941715782580222,
            "f1": 0.43428537418062174,
            "f1_weighted": 0.7328347607517478
          },
          {
            "accuracy": 0.704649639816634,
            "f1": 0.44515282127247974,
            "f1_weighted": 0.729114602085298
          },
          {
            "accuracy": 0.639161755075311,
            "f1": 0.4177467115034224,
            "f1_weighted": 0.6664739123513768
          },
          {
            "accuracy": 0.6699410609037328,
            "f1": 0.41165644374695565,
            "f1_weighted": 0.6928848873535991
          },
          {
            "accuracy": 0.6797642436149313,
            "f1": 0.4308827072995052,
            "f1_weighted": 0.7139975906636254
          },
          {
            "accuracy": 0.6719056974459725,
            "f1": 0.4344842774085819,
            "f1_weighted": 0.6972734196022903
          },
          {
            "accuracy": 0.6673215455140799,
            "f1": 0.4594445096434361,
            "f1_weighted": 0.706932002989614
          },
          {
            "accuracy": 0.633267845448592,
            "f1": 0.4193713481286648,
            "f1_weighted": 0.668246185532327
          },
          {
            "accuracy": 0.6843483955468238,
            "f1": 0.43960583988999846,
            "f1_weighted": 0.7105516869985236
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}