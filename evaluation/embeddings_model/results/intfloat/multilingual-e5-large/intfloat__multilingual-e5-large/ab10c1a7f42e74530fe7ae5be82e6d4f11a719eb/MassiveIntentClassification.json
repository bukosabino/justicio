{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 19.76087713241577,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.6470073974445192,
        "f1": 0.6310214609644293,
        "f1_weighted": 0.6436837513584948,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6470073974445192,
        "scores_per_experiment": [
          {
            "accuracy": 0.6741761936785474,
            "f1": 0.6512228307084073,
            "f1_weighted": 0.6684080825723471
          },
          {
            "accuracy": 0.6546738399462004,
            "f1": 0.6376361286183498,
            "f1_weighted": 0.6566169114439243
          },
          {
            "accuracy": 0.632481506388702,
            "f1": 0.624393539224367,
            "f1_weighted": 0.6321266745990587
          },
          {
            "accuracy": 0.6526563550773369,
            "f1": 0.6345272333124827,
            "f1_weighted": 0.6574592419993966
          },
          {
            "accuracy": 0.6422326832548756,
            "f1": 0.6195091613673828,
            "f1_weighted": 0.6343266017638244
          },
          {
            "accuracy": 0.6375252185608608,
            "f1": 0.6338831279478526,
            "f1_weighted": 0.6347787222429591
          },
          {
            "accuracy": 0.6489576328177539,
            "f1": 0.6345956030306216,
            "f1_weighted": 0.6426186783790114
          },
          {
            "accuracy": 0.6344989912575656,
            "f1": 0.6089359368087541,
            "f1_weighted": 0.6331084222537378
          },
          {
            "accuracy": 0.6267652992602556,
            "f1": 0.6229109823141604,
            "f1_weighted": 0.6115157007846054
          },
          {
            "accuracy": 0.6661062542030934,
            "f1": 0.6426000663119137,
            "f1_weighted": 0.6658784775460829
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6552877520905066,
        "f1": 0.6202265822581658,
        "f1_weighted": 0.6505936208453924,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6552877520905066,
        "scores_per_experiment": [
          {
            "accuracy": 0.675848499754058,
            "f1": 0.6373415123186894,
            "f1_weighted": 0.6683655353684971
          },
          {
            "accuracy": 0.6591244466305952,
            "f1": 0.6259666827677907,
            "f1_weighted": 0.6538849368003509
          },
          {
            "accuracy": 0.6389572060993606,
            "f1": 0.6031764905555325,
            "f1_weighted": 0.6382117581459715
          },
          {
            "accuracy": 0.6497786522380719,
            "f1": 0.6044528580865534,
            "f1_weighted": 0.6502507419541558
          },
          {
            "accuracy": 0.6586325627151992,
            "f1": 0.6103464952553869,
            "f1_weighted": 0.6518200747569041
          },
          {
            "accuracy": 0.6625676340383669,
            "f1": 0.630959770801855,
            "f1_weighted": 0.6596876064340712
          },
          {
            "accuracy": 0.6483030004918839,
            "f1": 0.622416652567368,
            "f1_weighted": 0.6432411370805438
          },
          {
            "accuracy": 0.6522380718150517,
            "f1": 0.6172071576800932,
            "f1_weighted": 0.6483792375223332
          },
          {
            "accuracy": 0.6428922774225283,
            "f1": 0.6309803632326331,
            "f1_weighted": 0.6275587876194969
          },
          {
            "accuracy": 0.6645351696999509,
            "f1": 0.6194178393157558,
            "f1_weighted": 0.6645363927715999
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}