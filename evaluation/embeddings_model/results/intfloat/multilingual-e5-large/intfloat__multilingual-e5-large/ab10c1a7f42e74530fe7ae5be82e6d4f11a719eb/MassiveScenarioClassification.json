{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "evaluation_time": 10.508144617080688,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.689340954942838,
        "f1": 0.6814415958731015,
        "f1_weighted": 0.684599238297634,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.689340954942838,
        "scores_per_experiment": [
          {
            "accuracy": 0.7135171486213854,
            "f1": 0.707396787491918,
            "f1_weighted": 0.7112134622503993
          },
          {
            "accuracy": 0.7017484868863484,
            "f1": 0.6991731577400936,
            "f1_weighted": 0.698909749707669
          },
          {
            "accuracy": 0.703429724277068,
            "f1": 0.6827795148251238,
            "f1_weighted": 0.6960022150155442
          },
          {
            "accuracy": 0.660390047074647,
            "f1": 0.6539983013603253,
            "f1_weighted": 0.6590063992411666
          },
          {
            "accuracy": 0.6859448554135844,
            "f1": 0.6750047994378384,
            "f1_weighted": 0.674856195824311
          },
          {
            "accuracy": 0.6691324815063887,
            "f1": 0.6544214909997551,
            "f1_weighted": 0.6530695422655092
          },
          {
            "accuracy": 0.6882985877605918,
            "f1": 0.6789080194451139,
            "f1_weighted": 0.6841195755202121
          },
          {
            "accuracy": 0.6849361129791527,
            "f1": 0.6866799775271314,
            "f1_weighted": 0.6829274488516678
          },
          {
            "accuracy": 0.7074646940147948,
            "f1": 0.7048816176179851,
            "f1_weighted": 0.7065085719395983
          },
          {
            "accuracy": 0.6785474108944183,
            "f1": 0.6711722922857306,
            "f1_weighted": 0.6793792223602632
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6898671913428431,
        "f1": 0.6784455770714182,
        "f1_weighted": 0.6854763370931158,
        "hf_subset": "es",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.6898671913428431,
        "scores_per_experiment": [
          {
            "accuracy": 0.7127397934087555,
            "f1": 0.7033831106211523,
            "f1_weighted": 0.7105329985851567
          },
          {
            "accuracy": 0.6999508116084604,
            "f1": 0.6946142599469556,
            "f1_weighted": 0.7003488359657578
          },
          {
            "accuracy": 0.6989670437776685,
            "f1": 0.6855044507803725,
            "f1_weighted": 0.6940612897526253
          },
          {
            "accuracy": 0.6414166256763404,
            "f1": 0.6287791514369785,
            "f1_weighted": 0.6363481818276955
          },
          {
            "accuracy": 0.690113133300541,
            "f1": 0.6737844237263116,
            "f1_weighted": 0.6812603911940652
          },
          {
            "accuracy": 0.6768322675848499,
            "f1": 0.6618495853575518,
            "f1_weighted": 0.6642768371454628
          },
          {
            "accuracy": 0.6876537137235612,
            "f1": 0.6713162408667717,
            "f1_weighted": 0.681612763528513
          },
          {
            "accuracy": 0.691096901131333,
            "f1": 0.6884716079085146,
            "f1_weighted": 0.6887484320545538
          },
          {
            "accuracy": 0.7092966060009838,
            "f1": 0.705133496830295,
            "f1_weighted": 0.7067786987009043
          },
          {
            "accuracy": 0.690605017215937,
            "f1": 0.6716194432392777,
            "f1_weighted": 0.6907949421764245
          }
        ]
      }
    ]
  },
  "task_name": "MassiveScenarioClassification"
}