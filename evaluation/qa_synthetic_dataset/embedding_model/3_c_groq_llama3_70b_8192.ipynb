{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMSSvAKrSb_S",
    "outputId": "ceceb77e-1f1b-47e3-b1a0-92860da2326b"
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade datasets groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZFrT5tHSo_C"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiWFY-ZNU06l"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqbPhFpXSpEu"
   },
   "outputs": [],
   "source": [
    "INPUT_DATASET = \"dariolopez/justicio-BOE-A-1978-31229-constitucion-by-articles-qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHLl8TTvTNVN"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Como un experto en derecho y leyes españolas, tu tarea es responder preguntas sobre el Boletín Oficial del Estado (BOE) de España. Para ello, debes tener en cuenta y utilizar el contexto proporcionado para responder de forma precisa a la pregunta del usuario.\n",
    "Asegúrate de responder siempre en español. Si no conoces la respuesta o no tienes suficiente información para responderla, simplemente admítelo; no intentes inventar una respuesta.\n",
    "Deberás proporcionar detalles claros y precisos en tus respuestas, asegurándote de referenciar adecuadamente cualquier ley o reglamento pertinente. Tu objetivo es proporcionar respuestas útiles y precisas para ayudar a los usuarios a entender mejor el BOE y cómo se aplica a sus preguntas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPmL3T8GUkPL"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_CONTEXT = \"\"\"\n",
    "El contexto tiene un formato de lista, donde cada elemento será un diccionario con dos claves:\n",
    "[{'context': 'contexto necesario para contestar la pregunta', 'score': 0.8}]\n",
    "La clave 'context' contendrá la información necesaria para contestar a la pregunta y la clave 'score' será una puntuación de entre 0.0 y 1.0. Deberás dar más importancia al contexto cuanto mayor sea el score.\n",
    "En la respuesta no menciones nada sobre el contexto o los scores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LapT7LnnU-SH"
   },
   "outputs": [],
   "source": [
    "URL = \"http://localhost:5001/semantic_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_GR7364SpNc"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(INPUT_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iy7sZE4YYsvW"
   },
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get('GROQ_API_KEY'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRioe5m5YuL6",
    "outputId": "c8b51a6a-3395-49cd-f042-e7d550285312"
   },
   "outputs": [],
   "source": [
    "answers_groq = []\n",
    "contexts = []\n",
    "\n",
    "for idx, row in enumerate(dataset['train']):\n",
    "    time.sleep(20)  # groq limits: https://console.groq.com/settings/limits\n",
    "    try:\n",
    "        docs = requests.get(URL, params={'input_query': row['question'], 'collection_name': 'boe-bge-m3'}, timeout=60)\n",
    "        context_preprocessed = [{\"context\": doc[0]['page_content'], \"score\": doc[1]} for doc in docs.json()]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": SYSTEM_PROMPT_CONTEXT,\n",
    "            },\n",
    "            {\"role\": \"system\", \"content\": \"A continuación se proporciona el contexto:\"},\n",
    "            {\"role\": \"system\", \"content\": str(context_preprocessed)},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"A continuación se proporciona la pregunta del usuario:\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": row['question']},\n",
    "        ]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0,\n",
    "            max_tokens=2048,\n",
    "            stream=False,\n",
    "        )\n",
    "        answer = chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        answer = None\n",
    "\n",
    "    answers_groq.append(answer)\n",
    "    contexts.append(context_preprocessed)\n",
    "    print(f\"{idx+1} - {row['question']}\")\n",
    "    print(row['answer'])\n",
    "    print(answer)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answers_groq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "bhylwhSXZ0-h",
    "outputId": "ade768e9-a258-4138-8f2b-0f659a613fc6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column('context_qa', contexts)\n",
    "dataset['train'] = dataset['train'].add_column('response_groq_llama3_70b_8192', answers_groq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2zy4ooSX_13"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aX1MVv_UaayO"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = f\"{INPUT_DATASET}-bge-m3-groq_llama3_70b_8192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n80VJlyjaa03"
   },
   "outputs": [],
   "source": [
    "dataset.push_to_hub(output_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4TTC-adaa3u"
   },
   "outputs": [],
   "source": [
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
